---
tags:
  - Paper
links: 
Связи:
---
Low Rank Adaptation - метод [[Finetuning]] моделей.
Обычно используется для тюнинга больших моделей, например [[LLM  - Large Language Models]] или [[Diffusion model]]
Содержание:
- [[#Basics|Basics]]
- [[#More info|More info]]
- [[#Train methodology|Train methodology]]
- [[#Pluses and potential tasks|Pluses and potential tasks]]
- [[#Links|Links]]



## Basics

Суть метода:
Это метод, который замораживает предварительно обученные веса модели и вводит обучаемые матрицы каждый слой архитектуры. Т.е. мы изменяем каждый слой, чтоб он возращал не y, а y'
![[Pasted image 20240119133403.png]]

Т.к. современные модели очень большие, мы обучаем не матричку deltaW, а ее матричное разложение, позволяющее сильно снизить количество необходимых для файнтюнинга весов


## More info
Давайте обучим веса к каждому слоу для Downstream task.  Сделаем модельку-адаптер, и каждой слой будем складывать с его весами оригинал (W + deltW)
- Но тогда ведь доп моделька будет огромной!
- Не беда, мы обучим не веса напрямую, а две матрички, которые при умножении дадут нужную размерность, скажем от 100\*70 перейдем к 100\*2 + 2\*70
- Да, упадет точность, но т.к. нейронки основные веса хранят около 0, то сойдет ![[Pasted image 20240119134140.png]]
Аутпут будет получаться так
![[Pasted image 20240119134224.png]]



## Train methodology
- Замораживаем веса базовой модели
- Для каждого слоя делаем Low-Rank Adaptation
- Изначально одна матричка B инициализируется 0, а A из норм распределения
- Треним только их

![[Pasted image 20240119135854.png]]

## Pluses and potential tasks
- Очень небольшие модели-адаптеры (до 0.001 от размера основной)
- Можно держать Большую модель и кучу адаптеров рядом, и переключать их, и у тебя получается куча моделей как-бы, а в память загружена одна
- Возможность сочитания с другими методами файнтюнинга (такие как  prefix-tuning)
- Генерация не вызывает дополнительные задержки - можно явно подсчитать W = W0 + A\*B и использовать
- Подходит для разных задач:
	- Классификация текста
	- Генерация текста (в конкретную сторону или домен)
	- Генерация изображений в конкретном стиле


## Links
- paper https://arxiv.org/abs/2106.09685
- хорошая статья с основнами https://habr.com/ru/articles/747534/