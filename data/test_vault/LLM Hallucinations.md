---
tags:
  - LLM
links:
---
[[LLM  - Large Language Models]] легко могут глючить, ибо не слишком знают границы своих знаний, и при вопросах о затемненном для них топике, могут выдать что-то очень похожее на правду, но не являющейся правдой.
В частности вот [[ChatGPT]] врет про несуществующий продукт существующей компании

Можно попробовать уменьшить галюцинации, попросив модель найти релевантную информацию, или цитаты из текста,  затем ответить на вопрос, используя ее
- And one additional tactic to reduce hallucinations, in the case that you want the model to kind of generate answers based on a text, is to ask the model to first find any relevant quotes from the text and then ask it to use those quotes to kind of answer questions. And kind of having a way to trace the answer back to the source document is often pretty helpful to kind of reduce these hallucinations.


![[Pasted image 20230802234851.png]]![[Pasted image 20230802235359.png]]