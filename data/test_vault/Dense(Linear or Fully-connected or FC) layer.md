---
Связи: 
tags: 
links:
---
Полносвязный слой.
![[Pasted image 20241130101023.png]]
Посути каждный нейрончик представляет собой [[Logistic Regression]]
Каждый нейрон на вход получает N фич (например пикселей) и возращает 1 чиселко
Размер аутпута зависит от кол-ва нейронов

Размер тренируемвых весов - матрица W = N*M
- где N - количество входных фичей
- M - размер выхода и кол-во нейронов в слое

Получаемое преобразование
X*W = Z
где
- X - входные данные, размерность N\*in_size, N - кол-во данных, in_size - размерность каждого векторка
- W - веса - разм in_size\*N_neurons(out_size), где N_neurons - кол-во нейронов, т.е. желаемая аутпут размерность
- Z - аут - N\*N_neurons


Активации
- В середине сетки обычно [[Rectified Linear Unit (ReLU)]] или его модификации
- На выходе - [[Sigmoid Function]] часто
	-  Размерность, получаемая на выходе линейного слоя + активации N
	- Т.е. матричка становится вектором: (N\*N_neurons) -> N
	- т.к. все N_neurons, складывают свои ауты в одну функцию, и она выдает по ним чиселку

![[Pasted image 20230921233531.png]]