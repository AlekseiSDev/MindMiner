---
tags:
  - "#DL"
  - "#ML"
links:
---
Так ну че. Мы хотим оптимизировать наш [[Loss(Cost) Function]], у нас есть сеточка и гиперпараметры, которые настраиваем сами
Можно настроить [[Optimizers]]
Что еще? Настроить [[Learning rate]]!
Как это можно делать? С помощью [[Schedulers]]!

Еще можно сделать LR Warm-up, чтоб прогреть наши сложные оптимайзеры

Сюда же можно отнести методики [[Weights initialization]] - хотя это и уже часть нейронки, хотим ли мы их как-то инициализировать сами или нет - це гиперпараметр

![[Pasted image 20241207102821.png]]