---
Связи: 
tags:
  - ML
  - DL
links:
---
Подход к обучению моделей, которые учатся на неразмеченных данных, но задача стоит в [[Supervised learning]]
Например задача предсказания некст слова в предложении - где для подготовки корпуса нам подойдет практически любые текстовые данные. На это учился [[BERT]] и куча SoTA в [[NLP]]

Или задача предсказания небольшого кропнуто куска изображения, на че учатся [[Transformer Architecture]] в [[Computer Vision]]

## Basic
- 

![[Pasted image 20230930095803.png]]![[Pasted image 20230930101359.png]]![[Pasted image 20230930101411.png]]