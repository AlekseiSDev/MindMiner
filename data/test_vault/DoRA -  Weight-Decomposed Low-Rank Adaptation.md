---
tags:
  - "#Paper"
  - "#LLM"
links:
---
https://arxiv.org/pdf/2402.09353.pdf
https://magazine.sebastianraschka.com/p/lora-and-dora-from-scratch#:~:text=DoRA%20can%20be%20described%20in,the%20magnitude%20vector%20m%20separately.

Basics
Предлогается процедуру лоры [[Low Rank Adaptation (LoRA)]] разложить еще на отдельные части. Общая суть остается той-же - обучить Low Rank Adaptation, но теперь применяя репараметризацию.
За счет этой разницы


Бьют LoRA в LLM и multimodal моделей. И eRA
![[Pasted image 20240220154832.png]]
![[Pasted image 20240220154910.png]]

## Translate
### Abstract

