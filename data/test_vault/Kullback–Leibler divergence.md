---
tags:
  - Math
links:
---
Дивергенция Кульбака-Лейбнира
Расстояние (не удовлетворяет определению [[distance (расстояние)]]) между двумя распределениями
Матожидание логарифма вероятностей правых распределений на вероятности левых?

Не отрицательна, равна 0 если распределения совпадают
https://towardsdatascience.com/understanding-kl-divergence-f3ddc8dff254
https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence

![[Pasted image 20231213204712.png]]
![[Pasted image 20241130104658.png]]
## Formula

![[Pasted image 20231213204910.png]]


## Example
  
Хорошо, давайте рассмотрим два вероятностных распределения P и Q, каждое из которых содержит пять возможных исходов. Для примера, возьмем следующие вероятности для каждого распределения:
- Распределение P: P=[0.2,0.2,0.2,0.2,0.2]
- Распределение Q: Q=[0.1,0.1,0.3,0.3,0.2]
![[Pasted image 20231213205645.png]]