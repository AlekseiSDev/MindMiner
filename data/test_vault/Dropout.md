---
tags:
  - "#DL"
  - Math
links:
---
Kind of regularization
При обучении отключаем с некоторой вероятностью(p, hyperparameter) часть нейрончиков, при инференсе нормируем вероятности на его p: out = out * (1-p) - т.к. сигнал будет просто сильнее, дисперсия и среднее вырастет, нужно отнормировать
Хорошо рассмотрен в Байесовской статистике, оказывается его использование эквивалентно некоторому ансамблированию
Реализуется как [[NN Layers|layer]]

![[Pasted image 20241207112749.png]]