{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8594186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aa0f4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "page_content='Связи: Теги:\n",
      "\n",
      "Самое дешевое вино. Ибо самая большая микрозона. Алазанская долина - посути микс любых виноградов с долины. Поэтому его запасы не ограничены и оно самое дешевое - материал неограничен.' metadata={'source': '../../data/lesha_obsi_sample/Алазанская долина (wine).md'}\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.document_loaders import DirectoryLoader #, MarkdownLoader\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "# Path to your Obsidian markdown notes\n",
    "directory_path = \"../../data/lesha_obsi_sample\"\n",
    "\n",
    "# Initialize the DirectoryLoader to load .md files\n",
    "loader = DirectoryLoader(\n",
    "    directory_path,\n",
    "    glob=\"**/*.md\",\n",
    "    loader_cls=UnstructuredMarkdownLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"}\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "print(len(docs))\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "476f880c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "Связи: Теги:\n",
      "\n",
      "Самое дешевое вино. Ибо самая большая микрозона. Алазанская долина - посути микс любых виноградов с долины. Поэтому его запасы не ограничены и оно самое дешевое - материал неограничен.\n",
      "Связи: Теги: tags: - \"#Book\" - \"#SelfDev\"\n",
      "\n",
      "Рассмотреть, как моя рациональная и импульсивная личность ведут себя во время [[СВ_Испытание силы я буду]], [[СВ_Испытание силы я не буду]]\n",
      "\n",
      "1) Во время испы\n",
      "tags: links:\n",
      "\n",
      "Basics\n",
      "Связи: Теги: #Продуктивность\n",
      "Связи: [[SuperVised Learning]] Теги: #ML\n",
      "\n",
      "Задача [[Second brain/main/Supervised learning|Supervised learning]] машинного обучения, заключающаяся в том, чтоб разбить входные данные на 2 класса, бинарно\n"
     ]
    }
   ],
   "source": [
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Print the splits to verify\n",
    "print(len(splits))\n",
    "for split in splits[:5]:\n",
    "    print(split.page_content[:200])  # Print first 200 characters of each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2144e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Retriever\n",
    "# Embed\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56c3711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Грузия известна своими винами, в том числе белым полусладким вином. В Грузии используют уникальный способ приготовления вина с использованием квеври. На застольях в Грузии пьют один напиток, предпочтительно белое вино.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### RETRIEVAL and GENERATION ####\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "print(f\"prompt: {prompt}\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Question\n",
    "rag_chain.invoke(\"Расскажи о винах Грузии?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
